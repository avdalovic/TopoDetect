{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combinatorial Complex with 2 nodes and cells with ranks [0, 1] and sizes (2, 1) \n",
      "Combinatorial Complex with 3 nodes and cells with ranks [0, 1] and sizes (3, 2) \n",
      "Combinatorial Complex with 4 nodes and cells with ranks [0, 1, 2] and sizes (4, 2, 1) \n",
      "Combinatorial Complex with 5 nodes and cells with ranks [0, 1, 2] and sizes (5, 3, 1) \n",
      "Combinatorial Complex with 6 nodes and cells with ranks [0, 1, 2] and sizes (6, 3, 2) \n"
     ]
    }
   ],
   "source": [
    "import toponetx as tnx\n",
    "example = tnx.CombinatorialComplex()\n",
    "\n",
    "example.add_cell([1, 2], rank=1)\n",
    "print(example)\n",
    "\n",
    "example.add_cell([1, 3], rank=1)\n",
    "print(example)\n",
    "\n",
    "example.add_cell([1, 2, 4, 3], rank=2)\n",
    "print(example)\n",
    "\n",
    "example.add_cell([2, 5], rank=1)\n",
    "print(example)\n",
    "\n",
    "example.add_cell([2, 6, 4], rank=2)\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loading SWAT data from data/SWAT/SWATv0_train.csv and data/SWAT/SWATv0_test.csv...\n",
      "Using sample rate: 0.05\n",
      "Sampled data: train=24750 rows, test=22495 rows\n",
      "Test data contains 22495 samples:\n",
      "  - Normal samples: 0 (0.00%)\n",
      "  - Attack samples: 22495 (100.00%)\n",
      "\n",
      "Expected attacks from attack_utils.py: 32 attack scenarios\n",
      "Total components in the dataset: 51\n",
      "Building SWAT combinatorial complex...\n",
      "Adding 51 components as rank 0 cells\n",
      "Adding 86 specific component relationships as rank 1 cells\n",
      "  Added 1-cell: [MV101, FIT101] (valve affects flow)\n",
      "  Added 1-cell: [FIT101, LIT101] (flow affects level)\n",
      "  Added 1-cell: [LIT101, P101] (tank level controls pump)\n",
      "  Added 1-cell: [P101, FIT201] (pump to stage 2 flow meter)\n",
      "  Added 1-cell: [P102, FIT201] (backup pump to stage 2)\n",
      "  Added 1-cell: [FIT201, AIT202] (flow affects pH reading)\n",
      "  Added 1-cell: [FIT201, AIT201] (flow affects conductivity reading)\n",
      "  Added 1-cell: [FIT201, AIT203] (flow affects ORP reading)\n",
      "  Added 1-cell: [AIT201, P201] (conductivity controls NaCl dosing)\n",
      "  Added 1-cell: [AIT201, P202] (conductivity reading controls backup NaCl dosing)\n",
      "  Added 1-cell: [AIT202, P203] (pH reading controls HCl dosing)\n",
      "  Added 1-cell: [AIT202, P204] (pH reading controls backup HCl dosing)\n",
      "  Added 1-cell: [AIT203, P205] (ORP reading controls NaOCl dosing)\n",
      "  Added 1-cell: [AIT203, P206] (ORP reading controls backup NaOCl dosing)\n",
      "  Added 1-cell: [MV201, LIT301] (valve affects T301 level)\n",
      "  Added 1-cell: [MV201, FIT301] (valve affects flow in next stage)\n",
      "  Added 1-cell: [P201, MV201] (NaCl flow)\n",
      "  Added 1-cell: [P203, MV201] (HCl flow)\n",
      "  Added 1-cell: [P205, MV201] (NaOCl flow)\n",
      "  Added 1-cell: [P201, AIT201] (NaCl dosing affects conductivity)\n",
      "  Added 1-cell: [P202, AIT201] (backup NaCl dosing affects conductivity)\n",
      "  Added 1-cell: [P203, AIT202] (HCl dosing affects pH)\n",
      "  Added 1-cell: [P204, AIT202] (backup HCl dosing affects pH)\n",
      "  Added 1-cell: [P205, AIT203] (NaOCl dosing affects ORP)\n",
      "  Added 1-cell: [P206, AIT203] (backup NaOCl dosing affects ORP)\n",
      "  Added 1-cell: [LIT301, P302] (T301 level controls pump)\n",
      "  Added 1-cell: [LIT301, P301] (T301 level controls  backup pump)\n",
      "  Added 1-cell: [FIT301, LIT301] (flow affects T301 level)\n",
      "  Added 1-cell: [DPIT301, MV301] (diff pressure affects UF inlet valve)\n",
      "  Added 1-cell: [DPIT301, MV302] (diff pressure affects outlet valve)\n",
      "  Added 1-cell: [DPIT301, MV303] (diff pressure triggers backwash)\n",
      "  Added 1-cell: [DPIT301, MV304] (pressure triggers backwash)\n",
      "  Added 1-cell: [MV303, FIT301] (backwash drain valve affects flow)\n",
      "  Added 1-cell: [MV304, FIT301] (UF drain valve affects flow)\n",
      "  Added 1-cell: [MV302, LIT401] (water from uf to next stage)\n",
      "  Added 1-cell: [LIT401, P401] (tank level controls backup dechlorination)\n",
      "  Added 1-cell: [LIT401, P402] (tank level controls  dechlorination)\n",
      "  Added 1-cell: [P402, FIT401] (pump affects flow)\n",
      "  Added 1-cell: [P401, FIT401] (backup pump affects flow)\n",
      "  Added 1-cell: [P402, UV401] (pump to UV)\n",
      "  Added 1-cell: [P401, UV401] (backup pump to UV)\n",
      "  Added 1-cell: [UV401, AIT402] (UV affects ORP)\n",
      "  Added 1-cell: [FIT401, UV401] (flow affects UV operation)\n",
      "  Added 1-cell: [AIT402, P403] (ORP controls NaHSO3 dosing)\n",
      "  Added 1-cell: [AIT402, P404] (ORP controls backup NaHSO3 dosing)\n",
      "  Added 1-cell: [AIT401, UV401] (hardness affects UV control)\n",
      "  Added 1-cell: [P205, AIT402] (NaOCl affects ORP)\n",
      "  Added 1-cell: [LIT401, UV401] (tank level affects UV operation)\n",
      "  Added 1-cell: [P403, P501] (pump after UV affects RO feed pump)\n",
      "  Added 1-cell: [P404, P502] (pump after UV affects RO backup pump)\n",
      "  Added 1-cell: [P403, PIT501] (pump after UV affects pressure meter P501)\n",
      "  Added 1-cell: [P404, PIT501] (pump backup after UV affects pressure meter P501)\n",
      "  Added 1-cell: [FIT401, AIT401] (flow affects hardness reading)\n",
      "  Added 1-cell: [UV401, P403] (UV output triggers NaHSO3 dosing)\n",
      "  Added 1-cell: [UV401, P404] (UV output triggers backup NaHSO3 dosing)\n",
      "  Added 1-cell: [P501, PIT501] (pump to RO affects RO feed pressure)\n",
      "  Added 1-cell: [P502, PIT501] (pump backup to RO affects RO feed pressure)\n",
      "  Added 1-cell: [P501, AIT501] (pH monitoring)\n",
      "  Added 1-cell: [P501, AIT502] (ORP monitoring)\n",
      "  Added 1-cell: [P501, AIT503] (feed conductivity)\n",
      "  Added 1-cell: [P501, FIT501] (pump affects RO feed flow)\n",
      "  Added 1-cell: [P501, FIT502] (pump affects RO permeate flow)\n",
      "  Added 1-cell: [P501, FIT503] (pump affects RO reject flow)\n",
      "  Added 1-cell: [FIT504, P501] (recirculation flow affects pump)\n",
      "  Added 1-cell: [AIT504, PIT502] (permeate conductivity)\n",
      "  Added 1-cell: [PIT503, P602] (reject pressure affects pump)\n",
      "  Added 1-cell: [FIT503, PIT503] (reject flow affects pressure meter)\n",
      "  Added 1-cell: [FIT502, AIT504] (permeate flow affects conductivity)\n",
      "  Added 1-cell: [FIT502, PIT502] (permeate flow affects pressure meter)\n",
      "  Added 1-cell: [AIT501, P501] (pH controls RO feed pump)\n",
      "  Added 1-cell: [AIT502, P501] (ORP controls RO feed pump)\n",
      "  Added 1-cell: [PIT501, AIT501] (pressure affects pH monitoring)\n",
      "  Added 1-cell: [PIT501, AIT502] (pressure affects ORP monitoring)\n",
      "  Added 1-cell: [PIT501, AIT503] (pressure affects conductivity monitoring)\n",
      "  Added 1-cell: [PIT502, FIT502] (permeate pressure affects flow)\n",
      "  Added 1-cell: [PIT503, FIT503] (reject pressure affects flow)\n",
      "  Added 1-cell: [FIT504, AIT503] (recirculation affects feed conductivity)\n",
      "  Added 1-cell: [P602, MV303] (pressure affects backwash pump)\n",
      "  Added 1-cell: [P602, MV301] (pump controls backwash flow)\n",
      "  Added 1-cell: [FIT601, MV301] (backwash flow affects valve control)\n",
      "  Added 1-cell: [FIT601, MV303] (backwash flow affects valve control)\n",
      "  Added 1-cell: [FIT601, MV301] (backwash flow affects valve control)\n",
      "  Added 1-cell: [FIT601, MV303] (backwash flow affects valve control)\n",
      "  Added 1-cell: [P601, FIT601] (backup pump affects backwash flow)\n",
      "  Added 1-cell: [MV301, MV303] (backwash valves are interconnected)\n",
      "  Added 1-cell: [FIT601, DPIT301] (backwash flow affects differential pressure)\n",
      "  Successfully added 86 component relationships\n",
      "Adding PLC control groups as rank 2 cells\n",
      "  Attempting to add PLC_1 with components: ['FIT101', 'LIT101', 'MV101', 'P101']\n",
      "  Added rank 2 cell: PLC_1 with 4 components\n",
      "  Attempting to add PLC_2 with components: ['AIT201', 'AIT202', 'AIT203', 'FIT201', 'MV201', 'P201', 'P202', 'P203', 'P204', 'P205', 'P206']\n",
      "  Added rank 2 cell: PLC_2 with 11 components\n",
      "  Attempting to add PLC_3 with components: ['MV201', 'DPIT301', 'FIT301', 'LIT301', 'MV301', 'MV302', 'P301']\n",
      "  Added rank 2 cell: PLC_3 with 7 components\n",
      "  Attempting to add PLC_4 with components: ['AIT402', 'FIT401', 'LIT401', 'P401']\n",
      "  Added rank 2 cell: PLC_4 with 4 components\n",
      "  Attempting to add PLC_5 with components: ['AIT501', 'FIT501', 'FIT502', 'P501']\n",
      "  Added rank 2 cell: PLC_5 with 4 components\n",
      "  Successfully added 5 PLC control groups\n",
      "Complex built: Combinatorial Complex with 51 nodes and cells with ranks [0, 1, 2] and sizes (51, 74, 5) \n",
      "Preprocessing features...\n",
      "Normalized sensor features, mean: 168.1863, std: 19.4213\n",
      "Actuator encoding: state 0=[0,0,0], state 1=[0,1,0], state 2=[0,0,1]\n",
      "Preprocessed features shape: torch.Size([24750, 51, 3])\n",
      "Computing neighborhood matrices...\n",
      "Matrix dimensions - a0: torch.Size([51, 51]), a1: torch.Size([74, 74]), coa2: torch.Size([5, 5]), b1: torch.Size([51, 74]), b2: torch.Size([74, 5])\n",
      "Computing initial 1-cell features...\n",
      "Found 74 1-cells\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reasearchstudent/anaconda3/envs/topox/lib/python3.11/site-packages/scipy/sparse/_index.py:145: SparseEfficiencyWarning: Changing the sparsity structure of a csc_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m swat_complex \u001b[38;5;241m=\u001b[39m SWATComplex()\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# 4. Initialize datasets \u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m SWaTDataset(train_data, swat_complex)\n\u001b[1;32m     50\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m SWaTDataset(test_data, swat_complex)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# 5. Create dataloader with batch size 1 (as in your main function)\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/TDS_ICS_project/swat_anomaly_detection.py:49\u001b[0m, in \u001b[0;36mSWaTDataset.__init__\u001b[0;34m(self, data, swat_complex, feature_dim)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma0, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoa2, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_neighborhood_matrix()\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Compute initial features for 1-cells and 2-cells\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_initial_x1()\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_initial_x2()\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitialized SWaTDataset with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/TDS_ICS_project/swat_anomaly_detection.py:180\u001b[0m, in \u001b[0;36mSWaTDataset.compute_initial_x1\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# Average the features of the boundary nodes\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_samples):\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# Average features of connected 0-cells\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     edge_feat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_dim)\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m node_idx \u001b[38;5;129;01min\u001b[39;00m node_indices:\n\u001b[1;32m    182\u001b[0m         edge_feat \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_0[sample_idx, node_idx]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "# Import functions from your modules\n",
    "from utils.attack_utils import get_attack_indices, get_attack_sds, is_actuator\n",
    "from utils.swat_topology import SWATComplex\n",
    "from swat_anomaly_detection import load_swat_data, SWaTDataset\n",
    "\n",
    "# Set paths (use the same ones as in your main function)\n",
    "data_dir = \"data/SWAT\"\n",
    "train_path = os.path.join(data_dir, \"SWATv0_train.csv\")\n",
    "test_path = os.path.join(data_dir, \"SWATv0_test.csv\")\n",
    "\n",
    "# Set sampling rate (can adjust as needed)\n",
    "sample_rate = 0.05  # Using 5% of the data, same as in your main function\n",
    "\n",
    "# Load data with sampling\n",
    "print(\"Loading data...\")\n",
    "train_data, test_data = load_swat_data(train_path, test_path, sample_rate=sample_rate)\n",
    "\n",
    "# 1. Basic attack statistics\n",
    "normal_samples = (test_data['Normal/Attack'] == 0.0).sum()\n",
    "attack_samples = (test_data['Normal/Attack'] != 1.0).sum()\n",
    "attack_percentage = 100 * attack_samples / len(test_data)\n",
    "\n",
    "print(f\"Test data contains {len(test_data)} samples:\")\n",
    "print(f\"  - Normal samples: {normal_samples} ({100 * normal_samples / len(test_data):.2f}%)\")\n",
    "print(f\"  - Attack samples: {attack_samples} ({attack_percentage:.2f}%)\")\n",
    "\n",
    "# 2. Check if this aligns with expected SWAT attack patterns\n",
    "attacks, attack_labels = get_attack_indices(\"SWAT\")\n",
    "print(f\"\\nExpected attacks from attack_utils.py: {len(attacks)} attack scenarios\")\n",
    "\n",
    "# Get all component names (excluding Timestamp and Normal/Attack)\n",
    "component_names = [col for col in test_data.columns if col not in ['Timestamp', 'Normal/Attack']]\n",
    "print(f\"Total components in the dataset: {len(component_names)}\")\n",
    "\n",
    "# 3. Initialize SWAT complex for testing\n",
    "swat_complex = SWATComplex()\n",
    "\n",
    "# 4. Initialize datasets \n",
    "train_dataset = SWaTDataset(train_data, swat_complex)\n",
    "test_dataset = SWaTDataset(test_data, swat_complex)\n",
    "\n",
    "# 5. Create dataloader with batch size 1 (as in your main function)\n",
    "batch_size = 1\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 6. Analyze the test dataloader to confirm attacks are included\n",
    "print(\"\\nAnalyzing test_dataloader...\")\n",
    "attack_count = 0\n",
    "labels_in_dataloader = []\n",
    "\n",
    "# Sample a limited number of batches to avoid slow execution\n",
    "max_samples = min(1000, len(test_dataloader))\n",
    "for i, (x_0, x_1, x_2, a0, a1, coa2, b1, b2, label) in enumerate(test_dataloader):\n",
    "    if i >= max_samples:\n",
    "        break\n",
    "    labels_in_dataloader.append(label.item())\n",
    "    if label.item() == 1:  # Attack label\n",
    "        attack_count += 1\n",
    "\n",
    "print(f\"Sampled {max_samples} batches from test_dataloader:\")\n",
    "print(f\"  - Attacks in sampled batches: {attack_count} ({100 * attack_count / max_samples:.2f}%)\")\n",
    "\n",
    "# 7. Create a timeline visualization of attacks\n",
    "if max_samples > 100:\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    plt.plot(labels_in_dataloader, 'r-')\n",
    "    plt.title('Attack Timeline in Test Data (1 = Attack, 0 = Normal)')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Attack Label')\n",
    "    plt.ylim(-0.1, 1.1)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# 8. Check which components are targeted by attacks (using attack_utils.py)\n",
    "print(\"\\nAttack targets according to attack_utils.py:\")\n",
    "target_components = []\n",
    "for labels in attack_labels:\n",
    "    target_components.extend(labels)\n",
    "\n",
    "# Count occurrences\n",
    "target_counter = Counter(target_components)\n",
    "for component, count in target_counter.most_common(10):\n",
    "    print(f\"  - {component}: targeted in {count} attacks\")\n",
    "\n",
    "# 9. Verify if these components exist in the dataset\n",
    "missing_components = [comp for comp in target_counter.keys() if comp not in component_names]\n",
    "if missing_components:\n",
    "    print(f\"\\nWarning: {len(missing_components)} targeted components are not in the dataset: {missing_components}\")\n",
    "else:\n",
    "    print(\"\\nAll targeted components are present in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 samples in test_dataloader:\n",
      "Index | Label (1=Attack, 0=Normal)\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex | Label (1=Attack, 0=Normal)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, sample \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(test_dataloader):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# The label is the last element in each sample tuple\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     label \u001b[38;5;241m=\u001b[39m sample[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(label)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "# Simple script to check for attacks in test_dataloader\n",
    "import torch\n",
    "\n",
    "# Assuming test_dataloader is already created with your SWaTDataset and DataLoader\n",
    "\n",
    "# Count attack samples and show first 10\n",
    "attack_count = 0\n",
    "print(\"First 10 samples in test_dataloader:\")\n",
    "print(\"Index | Label (1=Attack, 0=Normal)\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "for i, sample in enumerate(test_dataloader):\n",
    "    # The label is the last element in each sample tuple\n",
    "    label = sample[-1].item()\n",
    "    \n",
    "    \n",
    "    # Count attacks\n",
    "    if label == 1:\n",
    "        attack_count += 1\n",
    "    \n",
    "    # Print first 10 samples\n",
    "    if i < 10:\n",
    "        print(f\"{i:5d} | {label}\")\n",
    "\n",
    "# Print attack statistics\n",
    "total_samples = len(test_dataloader)\n",
    "attack_percentage = (attack_count / total_samples) * 100\n",
    "\n",
    "print(\"\\nTest dataset statistics:\")\n",
    "print(f\"Total samples: {total_samples}\")\n",
    "print(f\"Attack samples: {attack_count} ({attack_percentage:.2f}%)\")\n",
    "print(f\"Normal samples: {total_samples - attack_count} ({100 - attack_percentage:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
